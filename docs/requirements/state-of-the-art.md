# Аналіз предметної області. Система аналізу медіа контенту

## Вступ

*[Вступ повинен містити короткий огляд всього документу.]*


## Основні визначення

*[Розділ містить визначення термінів та скорочень, які використовуються при аналізі предметної області.]*

## Підходи та способи вирішення завдання

Однією з проблем при проектуванні системи аналізу медіа-контенту є необхідність вибору правильного підходу до вирішення задачі. На сьогоднішній день існує багато напрямів і стратегій, а також сучасних рішень для завдань у цьому напрямі.<br>

Роботу систем аналізу медіа-контенту можна поділити на 2 етапи.

Перший етап – збір інформації. <br>
Найбільш оптимальним методом швидкого та якісного збору потрібної інформації є парсинг 
(синтаксичний аналіз). 
При великих потоках інформації доцільним є використання технології Big Data.

[Parsing](https://en.wikipedia.org/wiki/Parsing) – послідовний синтаксичний аналіз 
інформації, розміщеної на веб-сторінці за допомогою спеціально написаних 
програм/скриптів здатних швидко аналізувати контент та знаходити необхідну інформацію.

[Big Data](https://en.wikipedia.org/wiki/Big_data) – група технологій та методів, за 
допомогою яких аналізують та обробляють велику кількість даних (як структурованих так 
і неструктурованих), що не піддається обробці класичними способами через занадто 
великий об'єм.

Другий етап – оброка інформації. <br>
Весь зібраний матеріал необхідно обробити (відсортувати) для того щоб його можна було
подати у зручному для сприйняття вигляді. З цією метою використовується контент-аналіз. До ефективних методів контент-аналізу можна віднести:

[Data Mining](https://en.wikipedia.org/wiki/Data_mining) – процес напівавтоматичного аналізу великих баз даних з метою пошуку корисних фактів. Зазвичай поділяють на задачі класифікації, моделювання та прогнозування.

[Text Mining](https://en.wikipedia.org/wiki/Text_mining) – напрям інтелектуального аналізу даних (англ. Data Mining) та штучного інтелекту, метою якого є отримання інформації з колекцій текстових документів, ґрунтуючись на застосуванні ефективних, у практичному плані, методів машинного навчання та обробки природної мови. Інтелектуальний аналіз тексту використовує всі ті ж підходи до перероблювання інформації, що й інтелектуальний аналіз даних, однак різниця між цими напрямками проявляється лише в кінцевих методах, а також у тому, що інтелектуальний аналіз даних має справу зі сховищами та базами даних, а не електронними бібліотеками та корпусами текстів.

[Deep Learning](https://en.wikipedia.org/wiki/Deep_learning) – це галузь машинного навчання, що ґрунтується на наборі алгоритмів, які намагаються моделювати високорівневі абстракції в даних, застосовуючи глибинний граф із декількома обробними шарами, що побудовано з кількох лінійних або нелінійних перетворень.

Також для реалізації системи контент-аналізу доцільним є використання новітніх методів та технологій у цій галузі, таких як наприклад:

[TensorFlow](https://www.tensorflow.org/) – відкрита програмна бібліотека для машинного навчання цілій низці задач, розроблена компанією Google для задоволення її потреб у системах, здатних будувати та тренувати нейронні мережі для виявляння та розшифровування образів та кореляцій, аналогічно до навчання й розуміння, які застосовують люди.

[Word2vec](https://en.wikipedia.org/wiki/Word2vec) – одна з методик обробки природної мови. Алгоритм word2vec використовує нейромережну модель для навчання пов'язаностей слів із великого корпусу тексту. Щойно її натреновано, така модель може виявляти слова-синоніми, або підказувати додаткові слова для часткового речення. Як випливає з її назви, word2vec представляє кожне окреме слово певним переліком чисел, званим вектором.

[Apache Lucene](https://lucene.apache.org/) – це бібліотека, що дозволяє організувати повнотекстовий пошук по безлічі документів, тобто пошук з використанням заданих ключових слів. Основна реалізація даної бібліотеки написана на Java, але в той же час існують порти цієї бібліотеки на інші мови і платформи.

[Sphinx](https://sphinxsearch.com/) – система повнотекстового пошуку, відмінною особливістю якої є висока швидкість індексації та пошуку, а також інтеграція з існуючими СУБД (MySQL, PostgreSQL) та наявність API для поширених мов веб-програмування.

[Elasticsearch](https://www.elastic.co/) – пошуковий сервер, розроблений на базі Lucene. Надає розподілений, мультиарендний повнотекстовий пошуковий рушій з HTTP вебінтерфейсом і підтримкою безсхемних JSON документів.

## Порівняльна характеристика існуючих засобів вирішення завдання

*[Розділ містить опис існуючих програм, інформаційних систем, сервісів, тощо, призначених для вирішення 
завдання. Дається порівняльна характеристика властивостей FURPS:*
- *Functionality (функциональні вимоги)*
- *Usability (вимоги до зручності роботи)*
- *Reliability (вимоги до надійності)*
- *Performance (вимоги до продуктивності)*
- *Supportability (вимоги до підтримки)*

 *(у вигляді таблиці).]*

## Висновки

*[Робляться висновки щодо доцільності розробки нової або модифікації існуючої інформаційної системи, необхідності та способів інтеграції з системами(сервісами) третіх сторін, тощо.]*

## Посилання

*[Розділ містить повний список всіх документів, про які згадується.]*
